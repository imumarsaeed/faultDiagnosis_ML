{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(r\"C:\\Users\\MCSL-user\\Pictures\\1.0_constant_FaultDiagnosis_multihop_indoor_dataset.xlsx\")\n",
    "\n",
    "df0 = pd.read_excel(xls, 'normal')\n",
    "df1 = pd.read_excel(xls, 'hardover')\n",
    "df2 = pd.read_excel(xls, 'drift')\n",
    "df3 = pd.read_excel(xls, 'spike')\n",
    "df4 = pd.read_excel(xls, 'erratic')\n",
    "df5 = pd.read_excel(xls, 'dataloss')\n",
    "df6 = pd.read_excel(xls, 'random')\n",
    "df7 = pd.read_excel(xls, 'stuck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Training Data for simple Classification\n",
    "\n",
    "normal = df0[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "normal = normal.head(400)\n",
    "\n",
    "hardover = df1[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "hardover = hardover.head(400)\n",
    "\n",
    "drift = df2[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "drift = drift.head(400)\n",
    "\n",
    "spike = df3[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "spike = spike.head(400)\n",
    "\n",
    "erratic = df4[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "erratic = erratic.head(400)\n",
    "\n",
    "dataloss = df5[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "dataloss = dataloss.head(400)\n",
    "\n",
    "random = df6[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "random = random.head(400)\n",
    "\n",
    "stuck = df7[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "stuck = stuck.head(400)\n",
    "\n",
    "trainingData = pd.concat([normal, hardover, drift, spike, erratic, dataloss, random, stuck])\n",
    "trainingData['Label'] = 0\n",
    "\n",
    "trainingData.iloc[0:400, trainingData.columns.get_loc('Label')] = 0      \n",
    "trainingData.iloc[400:800, trainingData.columns.get_loc('Label')] = 1      \n",
    "trainingData.iloc[800:1200, trainingData.columns.get_loc('Label')] = 2   \n",
    "trainingData.iloc[1200:1600, trainingData.columns.get_loc('Label')] = 3   \n",
    "trainingData.iloc[1600:2000, trainingData.columns.get_loc('Label')] = 4  \n",
    "trainingData.iloc[2000:2400, trainingData.columns.get_loc('Label')] = 5   \n",
    "trainingData.iloc[2400:2800, trainingData.columns.get_loc('Label')] = 6   \n",
    "trainingData.iloc[2800:3200, trainingData.columns.get_loc('Label')] = 7 \n",
    "\n",
    "trainingData.to_excel(r\"C:\\Users\\MCSL-user\\Pictures\\trainingData.xlsx\", sheet_name='trainingData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Testing Data\n",
    "\n",
    "normal = df0[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "normal = normal.tail(200)\n",
    "\n",
    "hardover = df1[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "hardover = hardover.tail(200)\n",
    "\n",
    "drift = df2[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "drift = drift.tail(200)\n",
    "\n",
    "spike = df3[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "spike = spike.tail(200)\n",
    "\n",
    "erratic = df4[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "erratic = erratic.tail(200)\n",
    "\n",
    "dataloss = df5[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "dataloss = dataloss.tail(200)\n",
    "\n",
    "random = df6[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "random = random.tail(200)\n",
    "\n",
    "stuck = df7[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "stuck = stuck.tail(200)\n",
    "\n",
    "testingData = pd.concat([normal, hardover, drift, spike, erratic, dataloss, random, stuck])\n",
    "testingData['Label'] = 0\n",
    "\n",
    "testingData.iloc[0:200, testingData.columns.get_loc('Label')] = 0      \n",
    "testingData.iloc[200:400, testingData.columns.get_loc('Label')] = 1      \n",
    "testingData.iloc[400:600, testingData.columns.get_loc('Label')] = 2   \n",
    "testingData.iloc[600:800, testingData.columns.get_loc('Label')] = 3   \n",
    "testingData.iloc[800:1000, testingData.columns.get_loc('Label')] = 4  \n",
    "testingData.iloc[1000:1200, testingData.columns.get_loc('Label')] = 5   \n",
    "testingData.iloc[1200:1400, testingData.columns.get_loc('Label')] = 6   \n",
    "testingData.iloc[1400:1600, testingData.columns.get_loc('Label')] = 7\n",
    "\n",
    "testingData.to_excel(r\"C:\\Users\\MCSL-user\\Pictures\\testingData.xlsx\", sheet_name='testingData')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not Compile after this ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Training Data for OvR Manner\n",
    "\n",
    "# Total 600 samples = 400 Head Training - 200 Tail Testing\n",
    "\n",
    "\n",
    "normal = df0[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "normal = normal.head(400)\n",
    "\n",
    "hardover = df1[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "hardover = hardover.head(400)\n",
    "\n",
    "drift = df2[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "drift = drift.head(400)\n",
    "\n",
    "spike = df3[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "spike = spike.head(400)\n",
    "\n",
    "erratic = df4[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "erratic = erratic.head(400)\n",
    "\n",
    "dataloss = df5[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "dataloss = dataloss.head(400)\n",
    "\n",
    "random = df6[['1_T1','2_T2','3_H1','4_H2','5_T1','6_T2','7_H1','8_H2','9_T1','10_T2','11_H1','12_H2','13_T1','14_T2','15_H1','16_H2']]\n",
    "random = random.head(400)\n",
    "\n",
    "trainingData = pd.concat([normal, hardover, drift, spike, erratic, dataloss, random])\n",
    "trainingData['Label'] = 0   # Make Label column and insert value \"0\"\n",
    "\n",
    "trainingData.iloc[0:400, trainingData.columns.get_loc('Label')] = 1        # Normal 1 - Rest 0\n",
    "#trainingData.iloc[400:800, trainingData.columns.get_loc('Label')] = 1     # Hardover 1 - Rest 0\n",
    "#trainingData.iloc[800:1200, trainingData.columns.get_loc('Label')] = 1    # Drift 1 - Rest 0\n",
    "#trainingData.iloc[1200:1600, trainingData.columns.get_loc('Label')] = 1   # Spike 1 - Rest 0\n",
    "#trainingData.iloc[1600:2000, trainingData.columns.get_loc('Label')] = 1   # Erratic 1 - Rest 0\n",
    "#trainingData.iloc[2000:2400, trainingData.columns.get_loc('Label')] = 1   # Dataloss 1 - Rest 0\n",
    "#trainingData.iloc[2400:2800, trainingData.columns.get_loc('Label')] = 1   # Random 1 - Rest 0\n",
    "\n",
    "trainingData.to_excel(r\"C:\\Users\\MCSL-user\\Videos\\trainingData.xlsx\", sheet_name='trainingData0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
